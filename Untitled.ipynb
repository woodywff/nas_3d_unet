{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import nibabel as nib\n",
    "import os\n",
    "import glob\n",
    "from dev_tools.my_tools import print_red, minmax_normalize\n",
    "import pdb\n",
    "import numpy as np\n",
    "import yaml\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "\n",
    "def create_h5(source_folder, overwrite=False, config_yml='config.yml'):\n",
    "    '''\n",
    "    From the downloaded unziped folder to normalized .h5 file.\n",
    "    Return .h5 path.\n",
    "    '''\n",
    "    with open(config_yml) as f:\n",
    "        config = yaml.load(f,Loader=yaml.FullLoader)\n",
    "        \n",
    "    try:\n",
    "        affine = np.load(config['data']['affine_file'])\n",
    "    except FileNotFoundError:\n",
    "        affine = None\n",
    "    \n",
    "    dataset_type = source_folder.split('_')[-1].lower() # 'training' or 'validation' or 'testing'\n",
    "    target = os.path.join('data',dataset_type + '.h5')\n",
    "    \n",
    "    if os.path.exists(target) and not overwrite:\n",
    "        print('{:s} exists already.'.format(target))\n",
    "        return target\n",
    "    \n",
    "    with open(config['data']['mean_std_file'],'rb') as f:\n",
    "        mean_std_values = pickle.load(f)\n",
    "    \n",
    "    with h5py.File(target,'w') as h5_file:\n",
    "        img_dirs  = glob.glob(os.path.join(source_folder,'*/*' \n",
    "                                             if dataset_type == 'training' else '*'))\n",
    "        # for each subject:\n",
    "        for img_dir in tqdm(img_dirs,desc='writing {:s}'.format(target)):\n",
    "            if not os.path.isdir(img_dir):\n",
    "                continue\n",
    "            sub_id = img_dir.split('/')[-1]\n",
    "            h5_subid = h5_file.create_group(sub_id)\n",
    "            brain_widths = []\n",
    "            # different modalities:\n",
    "            for mod_file in os.listdir(img_dir): \n",
    "                img = nib.load(os.path.join(img_dir,mod_file))\n",
    "                if affine is None:\n",
    "                    affine = img.affine\n",
    "                    np.save(config['data']['affine_file'],affine)\n",
    "                img_npy = img.get_data()\n",
    "                mod = mod_file.split('_')[-1].split('.')[0]\n",
    "                if mod != 'seg':\n",
    "                    img_npy = normalize(img_npy,\n",
    "                                        mean = mean_std_values['{:s}_mean'.format(mod)],\n",
    "                                        std = mean_std_values['{:s}_std'.format(mod)])\n",
    "                    brain_widths.append(cal_outline(img_npy))\n",
    "                h5_subid.create_dataset(mod_file,data=img_npy)\n",
    "            start_edge = np.min(brain_widths,axis=0)[0]\n",
    "            end_edge = np.max(brain_widths,axis=0)[1]\n",
    "            brain_width = np.vstack((start_edge,end_edge))\n",
    "            h5_subid.create_dataset('brain_width',data=brain_width)\n",
    "        num_subs = len(h5_file)\n",
    "        \n",
    "    # update config.yml\n",
    "    with open(config_yml,'w') as f:\n",
    "        config['data'].update({'{:s}_h5'.format(dataset_type):target,\n",
    "                               'len_{:s}'.format(dataset_type):num_subs})\n",
    "        yaml.dump(config,f)\n",
    "        \n",
    "    return target\n",
    "\n",
    "def cal_outline(img_npy):\n",
    "    '''\n",
    "    Return an numpy array shape=(2,3), indicating the outline of the 3D brain area.\n",
    "    '''\n",
    "    brain_index = np.asarray(np.nonzero(img_npy))\n",
    "    start_edge = np.maximum(np.min(brain_index,axis=1)-1,0)\n",
    "    end_edge = np.minimum(np.max(brain_index,axis=1)+1,img_npy.shape)\n",
    "    \n",
    "    return np.vstack((start_edge,end_edge))\n",
    "\n",
    "def normalize(img_npy,mean,std,offset=0.1, mul_factor=100):\n",
    "    '''\n",
    "    Offset and mul_factor are used to make a distinction between brain voxel and background(zeros).\n",
    "    '''\n",
    "    brain_index = np.nonzero(img_npy)\n",
    "    img_npy[brain_index] = (minmax_normalize((img_npy[brain_index]-mean)/std) + offset) * mul_factor\n",
    "    return img_npy\n",
    "\n",
    "\n",
    "def cal_mean_std(source_folder, overwrite=False,config_yml = 'config.yml'):\n",
    "    '''\n",
    "    We only care about non-zero voxels which are voxels in brain areas.\n",
    "    This function calcultes the mean value and standard deviation of all non-zero voxels for each modalities.\n",
    "    Return a dictionary {'t1_mean': t1 mean value,'t1_std': t1 std value,'t2_mean': ...,'t2_std': ..., ...}\n",
    "    '''\n",
    "    with open(config_yml) as f:\n",
    "        config = yaml.load(f,Loader=yaml.FullLoader)\n",
    "        saved_path = config['data']['mean_std_file']\n",
    "    \n",
    "    if os.path.exists(saved_path) and not overwrite:\n",
    "        print('{:s} exists already.'.format(saved_path))\n",
    "        return\n",
    "    \n",
    "    sub_dirs = glob.glob(os.path.join(source_folder,'*/*')) # Specific Design\n",
    "    \n",
    "    mean_std_values = {}\n",
    "    \n",
    "    for mod in config['data']['all_mods']:\n",
    "        mean = 0\n",
    "        amount = 0\n",
    "        for sub_dir in tqdm(sub_dirs,\n",
    "                             desc='Calculating {:s}\\'s mean value'\n",
    "                             .format(mod)):\n",
    "            file_name = os.path.join(sub_dir,sub_dir.split('/')[-1]+'_{:s}.nii.gz'.format(mod))\n",
    "            img_npy = nib.load(file_name).get_data()\n",
    "            brain_area = img_npy[np.nonzero(img_npy)]\n",
    "            mean += np.sum(brain_area)\n",
    "            amount += len(brain_area)\n",
    "        mean /= amount\n",
    "        mean_std_values['{:s}_mean'.format(mod)] = round(mean,4)\n",
    "        print('{:s}\\'s mean value = {:.2f}'.format(mod,mean))\n",
    "        \n",
    "        std = 0\n",
    "        for sub_dir in tqdm(sub_dirs,\n",
    "                             desc='Calculating {:s}\\'s std value'\n",
    "                             .format(mod)):\n",
    "            file_name = os.path.join(sub_dir,sub_dir.split('/')[-1]+'_{:s}.nii.gz'.format(mod))\n",
    "            img_npy = nib.load(file_name).get_data()\n",
    "            brain_area = img_npy[np.nonzero(img_npy)]\n",
    "            std += np.sum((brain_area-mean)**2)\n",
    "        std = np.sqrt(std/amount)\n",
    "        mean_std_values['{:s}_std'.format(mod)] = round(std,4)\n",
    "        print('{:s}\\'s std value = {:.2f}'.format(mod,std))\n",
    "    print(mean_std_values)\n",
    "    \n",
    "    with open(saved_path,'wb') as f:\n",
    "        pickle.dump(mean_std_values,f)\n",
    "   \n",
    "                          \n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(config_yml='config.yml'):\n",
    "    '''\n",
    "    From downloaded unziped folders to Training.h5 Validation.h5 and Testing.h5 \n",
    "    '''\n",
    "    with open(config_yml) as f:\n",
    "        config = yaml.load(f,Loader=yaml.FullLoader)\n",
    "\n",
    "    cal_mean_std(source_folder=config['data']['source_train'])\n",
    "\n",
    "    create_h5(config['data']['source_train'])\n",
    "    create_h5(config['data']['source_val'])\n",
    "    create_h5(config['data']['source_test'])\n",
    "        \n",
    "preprocess() \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import yaml\n",
    "    \n",
    "def cross_val_split(num_sbjs, saved_path, num_folds=5, overwrite=False):\n",
    "    '''\n",
    "    To generate num_folds cross validation.\n",
    "    Return {'train_list_0':[],'val_list_0':[],...}\n",
    "    '''\n",
    "    if os.path.exists(saved_path) and not overwrite:\n",
    "        print('{:s} exists already.'.format(saved_path))\n",
    "        return\n",
    "    subid_indices = list(range(num_sbjs))\n",
    "    shuffle(subid_indices)\n",
    "    res = {}\n",
    "    for i in range(num_folds):\n",
    "        left = int(i/num_folds * num_sbjs)\n",
    "        right = int((i+1)/num_folds * num_sbjs)\n",
    "        res['train_list_{:d}'.format(i)] = subid_indices[:left] + subid_indices[right:]\n",
    "        res['val_list_{:d}'.format(i)] = subid_indices[left : right]\n",
    "    with open(saved_path,'wb') as f:\n",
    "        pickle.dump(res,f)\n",
    "    return\n",
    "\n",
    "# patching.py\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "def _patching_autofit(image_shape, patch_shape):\n",
    "    '''\n",
    "    Autofit patching strategy:\n",
    "        Symmetrically cover the image with patches without beyond boundary parts as far as possible.\n",
    "    image_shape: numpy.ndarray; shape = (3,)\n",
    "    patch_shape: numpy.ndarray; shape = (3,)\n",
    "    '''\n",
    "    n_dim = len(image_shape)\n",
    "    n_patches = np.ceil(image_shape / patch_shape)\n",
    "    start = np.zeros(n_dim)\n",
    "    step = np.zeros(n_dim)\n",
    "    for dim in range(n_dim):\n",
    "        if n_patches[dim] == 1:\n",
    "            start[dim] = -(patch_shape[dim] - image_shape[dim])//2\n",
    "            step[dim] = patch_shape[dim]\n",
    "        else:\n",
    "            overlap = np.ceil(n_patches[dim] * patch_shape[dim] - image_shape[dim])/(n_patches[dim] - 1)\n",
    "            overflow = n_patches[dim] * patch_shape[dim] - (n_patches[dim] - 1) * overlap - image_shape[dim]\n",
    "            start[dim] = - overflow//2\n",
    "            step[dim] = patch_shape[dim] - overlap\n",
    "    stop = start + n_patches * step\n",
    "    \n",
    "    patches = get_set_of_patch_indices(start, stop, step)\n",
    "    # add the centeric cube:\n",
    "    patches = np.vstack((patches, (image_shape - patch_shape)//2))\n",
    "    \n",
    "    return patches\n",
    "\n",
    "def patching(image_shape, patch_shape, overlap = None):\n",
    "    '''\n",
    "    Patching for each image.\n",
    "    image_shape: numpy.ndarray or tuple; shape = (3,)\n",
    "    patch_shape: numpy.ndarray or tuple; shape = (3,)\n",
    "    overlap: int or tuple or numpy.ndarray; shape = (3,); If None, only take the autofit patching strategy, \n",
    "                  otherwise symmetrically cover the image with patches as much as possible.\n",
    "                  This is for the augmentation consideration to verify the diversity of input samples.\n",
    "                  It may not be compulsary.\n",
    "    Return list of bottom left corner cords of patches.\n",
    "    '''\n",
    "#     pdb.set_trace()\n",
    "    image_shape = np.asarray(image_shape)\n",
    "    patch_shape = np.asarray(patch_shape)\n",
    "    \n",
    "    patches = _patching_autofit(image_shape, patch_shape)\n",
    "    if overlap is None:\n",
    "        return patches\n",
    "    \n",
    "    if isinstance(overlap, int):\n",
    "        overlap = np.asarray([overlap] * len(image_shape))\n",
    "    else:\n",
    "        overlap = np.asarray(overlap)\n",
    "    n_patches = np.ceil(image_shape / (patch_shape - overlap))\n",
    "    overflow = patch_shape * n_patches - (n_patches - 1) * overlap - image_shape\n",
    "    start = -overflow//2\n",
    "    step = patch_shape - overlap\n",
    "    stop = start + n_patches * step\n",
    "    \n",
    "    patches = np.vstack((patches,get_set_of_patch_indices(start, stop, step)))\n",
    "    \n",
    "    return patches\n",
    "\n",
    "def patching_hardcode128(image_shape, patch_shape, center_patch=True, pdb_set=False):\n",
    "#     pdb.set_trace()\n",
    "    image_shape = np.asarray(image_shape)\n",
    "    patch_shape = np.asarray(patch_shape)\n",
    "    if pdb_set:\n",
    "        if np.any(np.array(2*np.array(patch_shape) - np.array(image_shape))<=0):\n",
    "            print_red('error patch: too large')\n",
    "        if  np.any(np.array(image_shape-patch_shape)<=0):\n",
    "            print_red('error patch: too small')\n",
    "    start_2 = np.asarray(image_shape - patch_shape)\n",
    "    start_2[start_2 < 0] = 0\n",
    "    patches = np.array([[0,         0,         0         ],\n",
    "                        [start_2[0],0,         0         ],\n",
    "                        [0,         start_2[1],0         ],\n",
    "                        [0,         0,         start_2[2]],\n",
    "                        [start_2[0],start_2[1],0         ],\n",
    "                        [start_2[0],start_2[1],start_2[2]],\n",
    "                        [start_2[0],0,         start_2[2]],\n",
    "                        [0,         start_2[1],start_2[2]]])\n",
    "    if center_patch:\n",
    "        patches = np.vstack((patches, (image_shape - patch_shape)//2))\n",
    "    return patches\n",
    "\n",
    "def get_set_of_patch_indices(start, stop, step):\n",
    "    return np.asarray(np.mgrid[start[0]:stop[0]:step[0], start[1]:stop[1]:step[1],\n",
    "                               start[2]:stop[2]:step[2]].reshape(3, -1).T, dtype=np.int)\n",
    "\n",
    "def create_id_index_patch_list(id_index_list, data_file, patch_shape, patch_overlap = None):\n",
    "    '''\n",
    "    id_index_list: id_index is the index of .h5.keys()\n",
    "    data_file: .h5 file path\n",
    "    patch_shape: shape = (3,)\n",
    "    patch_overlap: overlap among patches\n",
    "    Return: list of (subject id, bottom left corner coordinates of one patch)\n",
    "    '''\n",
    "    id_index_patch_list = []\n",
    "    with h5py.File(data_file,'r') as h5_file:\n",
    "        id_list = list(h5_file.keys())\n",
    "        for index in id_index_list:\n",
    "            brain_width = h5_file[id_list[index]]['brain_width']\n",
    "            image_shape = brain_width[1] - brain_width[0] + 1\n",
    "            patches = patching(image_shape, patch_shape, overlap = patch_overlap)\n",
    "            id_index_patch_list.extend(itertools.product([index], patches))\n",
    "    return id_index_patch_list\n",
    "\n",
    "def data_generator(indices_list, batch_size=1, n_labels=1, labels=None, augment=False, augment_flip=True,\n",
    "                   augment_distortion_factor=0.25, shuffle_index_list=True, permute=False, num_model=1, \n",
    "                   pred_specific=False,overlap_label=False,\n",
    "                  config_yml='config.yml'):\n",
    "    '''\n",
    "    Generator for training and validation datasets. \n",
    "    In this project training and val dataset both come from training.h5\n",
    "    Patching = True\n",
    "    Augmentation = True\n",
    "    Overlap_label = True\n",
    "    Pred_specific = True\n",
    "    '''\n",
    "#     pdb.set_trace()\n",
    "    with open(config_yml) as f:\n",
    "        config = yaml.load(f,Loader=yaml.FullLoader)\n",
    "    \n",
    "    data_file = config['data']['training_h5']\n",
    "    patch_shape = config['data']['patch_shape']\n",
    "    \n",
    "    while True:\n",
    "        x_list = []\n",
    "        y_list = []\n",
    "        id_index_patch_list = create_id_index_patch_list(indices_list, data_file, patch_shape)\n",
    "\n",
    "        if shuffle_index_list:\n",
    "            shuffle(id_index_patch_list)\n",
    "        while len(id_index_patch_list) > 0:\n",
    "            id_index_patch = id_index_patch_list.pop()\n",
    "            add_data(x_list, y_list, data_file, id_index_patch, augment=augment, augment_flip=augment_flip,\n",
    "                     augment_distortion_factor=augment_distortion_factor, patch_shape=patch_shape,\n",
    "                     permute=permute)\n",
    "            if len(x_list) == batch_size or (len(index_list) == 0 and len(x_list) > 0):\n",
    "                yield convert_data(x_list, y_list, n_labels=n_labels, \n",
    "                                   labels=labels, num_model=num_model,overlap_label=overlap_label)\n",
    "#                 convert_data(x_list, y_list, n_labels=n_labels, labels=labels, num_model=num_model)\n",
    "                x_list = list()\n",
    "                y_list = list()\n",
    "    return\n",
    "\n",
    "from augment import augment_data, random_permutation_x_y\n",
    "\n",
    "\n",
    "def add_data(x_list, y_list, data_file, id_index_patch, \n",
    "             augment=False, augment_flip=False, augment_distortion_factor=0.25,\n",
    "             patch_shape=False, permute=False, skip_health = Trueï¼Œ affine_file = 'data/affine.npy'):\n",
    "    '''\n",
    "    add qualified x,y to the generator list\n",
    "    '''\n",
    "#     pdb.set_trace()\n",
    "    # data.shape = (4,_,_,_), truth.shape = (1,_,_,_):\n",
    "    data, truth = get_data_from_file(data_file, id_index_patch, patch_shape)\n",
    "    \n",
    "    # skip empty images\n",
    "    if np.all(data == 0):\n",
    "        return\n",
    "    # skip none tumor images\n",
    "    if skip_health and np.all(truth==0):\n",
    "        return\n",
    "    \n",
    "    if augment:\n",
    "        affine = np.load(affine_file)\n",
    "        data, truth = augment_data(data, truth, affine, flip=augment_flip, \n",
    "                                   scale_deviation=augment_distortion_factor)\n",
    "\n",
    "    if permute:\n",
    "        assert data.shape[-1] == data.shape[-2] == data.shape[-3], 'Not a cubic patch!'\n",
    "        data, truth = random_permutation_x_y(data, truth)\n",
    "\n",
    "    x_list.append(data)\n",
    "    y_list.append(truth)\n",
    "    return\n",
    "\n",
    "import pdb\n",
    "from dev_tools.my_tools import print2d\n",
    "\n",
    "def get_data_from_file(data_file, id_index_patch, patch_shape):\n",
    "    '''\n",
    "    Load image patch from .h5 file and mix 4 modalities into one 4d ndarray. \n",
    "    \n",
    "    Return x.shape = (4,_,_,_); y.shape = (1,_,_,_)\n",
    "    '''\n",
    "#     pdb.set_trace()\n",
    "    id_index, patch = id_index_patch\n",
    "    \n",
    "    with h5py.File(data_file,'r') as h5_file:\n",
    "        sub_id = list(h5_file.keys())[id_index]\n",
    "        brain_width = h5_file[sub_id]['brain_width']\n",
    "        \n",
    "        data = []\n",
    "        truth = []\n",
    "        for name, img in h5_file[sub_id].items():\n",
    "            if name == 'brain_width':\n",
    "                continue\n",
    "            brain_wise_img = img[brain_width[0,0]:brain_width[1,0]+1,\n",
    "                                brain_width[0,1]:brain_width[1,1]+1,\n",
    "                                brain_width[0,2]:brain_width[1,2]+1]\n",
    "            if name.split('_')[-1].split('.')[0] == 'seg':\n",
    "                truth.append(brain_wise_img)\n",
    "            else:\n",
    "                data.append(brain_wise_img)\n",
    "    data = np.asarray(data)\n",
    "    truth = np.asarray(truth)\n",
    "    \n",
    "    x = get_patch_from_3d_data(data, patch_shape, patch)\n",
    "    y = get_patch_from_3d_data(truth, patch_shape, patch)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def get_patch_from_3d_data(data, patch_shape, patch_index):\n",
    "    \"\"\"\n",
    "    Returns a patch from a numpy array.\n",
    "    :param data: numpy array from which to get the patch.\n",
    "    :param patch_shape: shape/size of the patch.\n",
    "    :param patch_index: corner index of the patch.\n",
    "    :return: numpy array take from the data with the patch shape specified.\n",
    "    \"\"\"\n",
    "    patch_index = np.asarray(patch_index, dtype=np.int16)\n",
    "    patch_shape = np.asarray(patch_shape)\n",
    "    image_shape = data.shape[-3:]\n",
    "    if np.any(patch_index < 0) or np.any((patch_index + patch_shape) > image_shape):\n",
    "        data, patch_index = fix_out_of_bound_patch_attempt(data, patch_shape, patch_index)\n",
    "    return data[..., patch_index[0]:patch_index[0]+patch_shape[0], patch_index[1]:patch_index[1]+patch_shape[1],\n",
    "                patch_index[2]:patch_index[2]+patch_shape[2]]\n",
    "\n",
    "\n",
    "def fix_out_of_bound_patch_attempt(data, patch_shape, patch_index, ndim=3):\n",
    "    \"\"\"\n",
    "    Pads the data and alters the patch index so that a patch will be correct.\n",
    "    :param data:\n",
    "    :param patch_shape:\n",
    "    :param patch_index:\n",
    "    :return: padded data, fixed patch index\n",
    "    \"\"\"\n",
    "    image_shape = data.shape[-ndim:]\n",
    "    pad_before = np.abs((patch_index < 0) * patch_index)\n",
    "    pad_after = np.abs(((patch_index + patch_shape) > image_shape) * ((patch_index + patch_shape) - image_shape))\n",
    "    pad_args = np.stack([pad_before, pad_after], axis=1)\n",
    "    if pad_args.shape[0] < len(data.shape):\n",
    "        pad_args = [[0, 0]] * (len(data.shape) - pad_args.shape[0]) + pad_args.tolist()\n",
    "#     data = np.pad(data, pad_args, mode=\"edge\")\n",
    "    data = np.pad(data, pad_args, 'constant',constant_values=0)\n",
    "    patch_index += pad_before\n",
    "    return data, patch_index\n",
    "\n",
    "\n",
    "def get_training_and_validation_generators(config_yml='config.yml',for_final_training=False):\n",
    "    '''\n",
    "    for_final_training: if True, all subjects would be trained.\n",
    "    '''\n",
    "    with open(config_yml) as f:\n",
    "        config = yaml.load(f,Loader=yaml.FullLoader)\n",
    "        \n",
    "    # split for cross validation\n",
    "    cross_val_file = config['data']['cross_val_indices']\n",
    "    cross_val_split(config['data']['len_training'], cross_val_file)\n",
    "    \n",
    "    # load indices list for training and validation\n",
    "    with open(cross_val_file,'rb') as f:\n",
    "        cross_val_indices = pickle.load(f)\n",
    "\n",
    "    train_indices = cross_val_indices['train_list_0']\n",
    "    val_indices = cross_val_indices['val_list_0']\n",
    "    if for_final_training:\n",
    "        train_indices += val_indices\n",
    "    \n",
    "    # generator for training and validation\n",
    "    n_lables = len(config['generator']['labels'])\n",
    "\n",
    "#     training_generator = data_generator(data_file, training_list,\n",
    "#                                         batch_size=batch_size,\n",
    "# #                                         n_labels=n_labels,\n",
    "# #                                         labels=labels,\n",
    "# #                                         augment=augment,\n",
    "# #                                         augment_flip=augment_flip,\n",
    "# #                                         augment_distortion_factor=augment_distortion_factor,\n",
    "# #                                         patch_shape=patch_shape,\n",
    "# #                                         patch_overlap=validation_patch_overlap,\n",
    "# #                                         patch_start_offset=training_patch_start_offset,\n",
    "# #                                         skip_blank=skip_blank,\n",
    "# #                                         permute=permute,\n",
    "# #                                         num_model=num_model,\n",
    "# #                                         pred_specific=pred_specific,\n",
    "#                                         overlap_label=overlap_label)\n",
    "        \n",
    "# get_training_and_validation_generators()\n",
    "# def get_training_and_validation_generators(data_file, batch_size, n_labels, training_keys_file, \n",
    "#                                            validation_keys_file,\n",
    "#                                            data_split=0.8, overwrite=False, labels=None, augment=False,\n",
    "#                                            augment_flip=True, augment_distortion_factor=0.25, \n",
    "#                                            patch_shape=None,\n",
    "#                                            validation_patch_overlap=0, training_patch_start_offset=None,\n",
    "#                                            validation_batch_size=None, skip_blank=True, permute=False,\n",
    "#                                            num_model=1,\n",
    "#                                            pred_specific=False, overlap_label=True,\n",
    "#                                            for_final_val=False):\n",
    "#     pass\n",
    "    #     pdb.set_trace()\n",
    "#     if not validation_batch_size:\n",
    "#         validation_batch_size = batch_size\n",
    "\n",
    "#     training_list, validation_list = get_validation_split(data_file,\n",
    "#                                                           data_split=data_split,\n",
    "#                                                           overwrite=overwrite,\n",
    "#                                                           training_file=training_keys_file,\n",
    "#                                                           validation_file=validation_keys_file)\n",
    "#     if for_final_val:\n",
    "#         training_list = training_list + validation_list\n",
    "\n",
    "#     training_generator = data_generator(data_file, training_list,\n",
    "#                                         batch_size=batch_size,\n",
    "#                                         n_labels=n_labels,\n",
    "#                                         labels=labels,\n",
    "#                                         augment=augment,\n",
    "#                                         augment_flip=augment_flip,\n",
    "#                                         augment_distortion_factor=augment_distortion_factor,\n",
    "#                                         patch_shape=patch_shape,\n",
    "#                                         patch_overlap=validation_patch_overlap,\n",
    "#                                         patch_start_offset=training_patch_start_offset,\n",
    "#                                         skip_blank=skip_blank,\n",
    "#                                         permute=permute,\n",
    "#                                         num_model=num_model,\n",
    "#                                         pred_specific=pred_specific,\n",
    "#                                         overlap_label=overlap_label)\n",
    "\n",
    "#     validation_generator = data_generator(data_file, validation_list,\n",
    "#                                           batch_size=validation_batch_size,\n",
    "#                                           n_labels=n_labels,\n",
    "#                                           labels=labels,\n",
    "#                                           patch_shape=patch_shape,\n",
    "#                                           patch_overlap=validation_patch_overlap,\n",
    "#                                           skip_blank=skip_blank,\n",
    "#                                           num_model=num_model,\n",
    "#                                           pred_specific=pred_specific,\n",
    "#                                           overlap_label=overlap_label)\n",
    "\n",
    "#     # Set the number of training and testing samples per epoch correctly\n",
    "#     #     pdb.set_trace()\n",
    "#     if os.path.exists('num_patches_training.npy'):\n",
    "#         num_patches_training = int(np.load('num_patches_training.npy'))\n",
    "#     else:\n",
    "#         num_patches_training = get_number_of_patches(data_file, training_list, patch_shape,\n",
    "#                                                        skip_blank=skip_blank,\n",
    "#                                                        patch_start_offset=training_patch_start_offset,\n",
    "#                                                        patch_overlap=validation_patch_overlap,\n",
    "#                                                        pred_specific=pred_specific)\n",
    "#         np.save('num_patches_training', num_patches_training)\n",
    "#     num_training_steps = get_number_of_steps(num_patches_training, batch_size)\n",
    "#     print(\"Number of training steps in each epoch: \", num_training_steps)\n",
    "\n",
    "#     if os.path.exists('num_patches_val.npy'):\n",
    "#         num_patches_val = int(np.load('num_patches_val.npy'))\n",
    "#     else:\n",
    "#         num_patches_val = get_number_of_patches(data_file, validation_list, patch_shape,\n",
    "#                                                  skip_blank=skip_blank,\n",
    "#                                                  patch_overlap=validation_patch_overlap,\n",
    "#                                                  pred_specific=pred_specific)\n",
    "#         np.save('num_patches_val', num_patches_val)\n",
    "#     num_validation_steps = get_number_of_steps(num_patches_val, validation_batch_size)\n",
    "#     print(\"Number of validation steps in each epoch: \", num_validation_steps)\n",
    "\n",
    "#     return training_generator, validation_generator, num_training_steps, num_validation_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.load('data/affine.npy')\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.asarray([-5,1,9])\n",
    "a = a[...,np.newaxis]\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from .utils import pickle_dump, pickle_load\n",
    "from .patches import compute_patch_indices, get_random_nd_index, get_patch_from_3d_data, compute_patch_indices_for_prediction\n",
    "from .augment import augment_data, random_permutation_x_y\n",
    "\n",
    "import pdb\n",
    "from dev_tools.my_tools import print_red\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "\n",
    "class Generator():\n",
    "    def __init__(self, h5_file_handle, index_list, batch_size=1, \n",
    "                 n_labels=1, labels=None, augment=True, \n",
    "                 augment_flip=True, augment_distortion_factor=0.25, \n",
    "                 patch_shape=None, patch_overlap=0, patch_start_offset=None,\n",
    "                 shuffle_index_list=True, skip_blank=True, permute=False, \n",
    "                 num_model=1, pred_specific=False,overlap_label=False):\n",
    "        with open(config_file) as f:\n",
    "            config = yaml.load(f,Loader=yaml.FullLoader)\n",
    "\n",
    "    def get_number_of_steps(n_samples, batch_size):\n",
    "        if n_samples <= batch_size:\n",
    "            return n_samples\n",
    "        elif np.remainder(n_samples, batch_size) == 0:\n",
    "            return n_samples//batch_size\n",
    "        else:\n",
    "            return n_samples//batch_size + 1\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def get_number_of_patches(data_file, index_list, patch_shape=None, patch_overlap=0, patch_start_offset=None,\n",
    "                              skip_blank=True,pred_specific=False):\n",
    "        if patch_shape:\n",
    "            index_list = create_patch_index_list(index_list, data_file, patch_shape, patch_overlap,\n",
    "                                                 patch_start_offset,pred_specific=pred_specific)\n",
    "            count = 0\n",
    "            for index in tqdm(index_list):\n",
    "                x_list = list()\n",
    "                y_list = list()\n",
    "                add_data(x_list, y_list, data_file, index, skip_blank=skip_blank, patch_shape=patch_shape)\n",
    "                if len(x_list) > 0:\n",
    "                    count += 1\n",
    "            return count\n",
    "        else:\n",
    "            return len(index_list)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    def add_data(x_list, y_list, data_file, index, augment=False, augment_flip=False, augment_distortion_factor=0.25,\n",
    "                 patch_shape=False, skip_blank=True, permute=False):\n",
    "        '''\n",
    "        add qualified x,y to the generator list\n",
    "        '''\n",
    "    #     pdb.set_trace()\n",
    "        data, truth = get_data_from_file(data_file, index, patch_shape=patch_shape)\n",
    "\n",
    "        if np.sum(truth) == 0:\n",
    "            return\n",
    "        if augment:\n",
    "            affine = np.load('affine.npy')\n",
    "            data, truth = augment_data(data, truth, affine, flip=augment_flip, scale_deviation=augment_distortion_factor)\n",
    "\n",
    "        if permute:\n",
    "            if data.shape[-3] != data.shape[-2] or data.shape[-2] != data.shape[-1]:\n",
    "                raise ValueError(\"To utilize permutations, data array must be in 3D cube shape with all dimensions having \"\n",
    "                                 \"the same length.\")\n",
    "            data, truth = random_permutation_x_y(data, truth[np.newaxis])\n",
    "        else:\n",
    "            truth = truth[np.newaxis]\n",
    "\n",
    "        if not skip_blank or np.any(truth != 0):\n",
    "            x_list.append(data)\n",
    "            y_list.append(truth)\n",
    "\n",
    "\n",
    "    def get_data_from_file(data_file, index, patch_shape=None):\n",
    "    #     pdb.set_trace()\n",
    "        if patch_shape:\n",
    "            index, patch_index = index\n",
    "            data, truth = get_data_from_file(data_file, index, patch_shape=None)\n",
    "            x = get_patch_from_3d_data(data, patch_shape, patch_index)\n",
    "            y = get_patch_from_3d_data(truth, patch_shape, patch_index)\n",
    "        else:\n",
    "            brain_width = data_file.root.brain_width[index]\n",
    "            x = np.array([modality_img[index,0,\n",
    "                                       brain_width[0,0]:brain_width[1,0]+1,\n",
    "                                       brain_width[0,1]:brain_width[1,1]+1,\n",
    "                                       brain_width[0,2]:brain_width[1,2]+1] \n",
    "                          for modality_img in [data_file.root.t1,\n",
    "                                               data_file.root.t1ce,\n",
    "                                               data_file.root.flair,\n",
    "                                               data_file.root.t2]])\n",
    "            y = data_file.root.truth[index, 0,\n",
    "                                     brain_width[0,0]:brain_width[1,0]+1,\n",
    "                                     brain_width[0,1]:brain_width[1,1]+1,\n",
    "                                     brain_width[0,2]:brain_width[1,2]+1]\n",
    "        return x, y\n",
    "\n",
    "\n",
    "    def convert_data(x_list, y_list, n_labels=1, labels=None, num_model=1,overlap_label=False):\n",
    "    #     pdb.set_trace()\n",
    "        x = np.asarray(x_list)\n",
    "        y = np.asarray(y_list)\n",
    "        if n_labels == 1:\n",
    "            y[y > 0] = 1\n",
    "        elif n_labels > 1:\n",
    "            if overlap_label:\n",
    "                y = get_multi_class_labels_overlap(y, n_labels=n_labels, labels=labels)\n",
    "            else:\n",
    "                y = get_multi_class_labels(y, n_labels=n_labels, labels=labels)\n",
    "        if num_model == 1:\n",
    "            return x, y\n",
    "        else:\n",
    "            return [x]*num_model, y\n",
    "\n",
    "\n",
    "    def get_multi_class_labels_overlap(data, n_labels=3, labels=(1,2,4)):\n",
    "        \"\"\"\n",
    "        4: ET\n",
    "        1+4: TC\n",
    "        1+2+4: WT\n",
    "        \"\"\"\n",
    "    #     pdb.set_trace()\n",
    "        new_shape = [data.shape[0], n_labels] + list(data.shape[2:])\n",
    "        y = np.zeros(new_shape, np.int8)\n",
    "\n",
    "        y[:,0][np.logical_or(data[:,0] == 1,data[:,0] == 4)] = 1    #1\n",
    "        y[:,1][np.logical_or(data[:,0] == 1,data[:,0] == 2, data[:,0] == 4)] = 1 #2\n",
    "        y[:,2][data[:,0] == 4] = 1    #4\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[[  0   0   0]\n",
      " [  0   0  27]\n",
      " [  0 112   0]\n",
      " [  0 112  27]\n",
      " [112   0   0]\n",
      " [112   0  27]\n",
      " [112 112   0]\n",
      " [112 112  27]\n",
      " [ 56  56  13]]\n",
      "\n",
      "\n",
      "[[  0   0   0]\n",
      " [  0   0  27]\n",
      " [  0 112   0]\n",
      " [  0 112  27]\n",
      " [112   0   0]\n",
      " [112   0  27]\n",
      " [112 112   0]\n",
      " [112 112  27]\n",
      " [ 56  56  13]\n",
      " [-56 -56 -43]\n",
      " [-56 -56  69]\n",
      " [-56  56 -43]\n",
      " [-56  56  69]\n",
      " [-56 168 -43]\n",
      " [-56 168  69]\n",
      " [ 56 -56 -43]\n",
      " [ 56 -56  69]\n",
      " [ 56  56 -43]\n",
      " [ 56  56  69]\n",
      " [ 56 168 -43]\n",
      " [ 56 168  69]\n",
      " [168 -56 -43]\n",
      " [168 -56  69]\n",
      " [168  56 -43]\n",
      " [168  56  69]\n",
      " [168 168 -43]\n",
      " [168 168  69]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# temp = time.time()\n",
    "# print(patching_autofit((240,240,155),(128,128,128)))\n",
    "# print(time.time()-temp)\n",
    "# temp = time.time()\n",
    "# print(patching_hardcode128((240,240,155),(128,128,128)))\n",
    "# print(time.time()-temp)\n",
    "# print(patching((240,240,155),(128,128,128)))\n",
    "\n",
    "# print(np.vstack((a,b)))\n",
    "print('\\n')\n",
    "print(patching((240,240,155),(128,128,128)))\n",
    "print('\\n')\n",
    "print(patching((240,240,155),(128,128,128),overlap=16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float('inf') == float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14,  0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array([8,6+12]) -18) % 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'a':1,'b':2}\n",
    "with open('test.pkl','wb') as f:\n",
    "    pickle.dump(a,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/mean_std.pkl','rb') as f:\n",
    "    res = pickle.load(f)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([1,2,3,50,34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([np.mean([1,34]),np.mean([2,3,50])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
